#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DEEP REVERSE ENGINEERING v2.0 - TÃŒM QUY LUáº¬T áº¨N
=================================================
PhÃ¢n tÃ­ch thá»‘ng kÃª chuyÃªn sÃ¢u Ä‘á»ƒ phÃ¡t hiá»‡n:
1. Machine Bias (sá»‘ bá»‹ thiÃªn lá»‡ch)
2. Position Bias (thiÃªn vá»‹ vá»‹ trÃ­)
3. Autocorrelation (tÆ°Æ¡ng quan giá»¯a cÃ¡c ká»³)  
4. Cycle Detection (chu ká»³ áº©n)
5. Gap Analysis (khoáº£ng cÃ¡ch xuáº¥t hiá»‡n)
6. Pair Correlation (cáº·p sá»‘ hay Ä‘i cÃ¹ng)
7. Sum/Modular Patterns (quy luáº­t tá»•ng/dÆ°)
8. Day-of-week Bias (thiÃªn vá»‹ theo ngÃ y)
9. Hot/Cold Streaks (chuá»—i nÃ³ng/láº¡nh)
10. Transition Matrix (ma tráº­n chuyá»ƒn tiáº¿p)
"""

import numpy as np
import json
import os
import sys
from collections import Counter, defaultdict
from itertools import combinations
from datetime import datetime
from scipy import stats

def load_draws(filepath):
    """Load draws from jsonl file."""
    draws = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)
                if 'result' in data:
                    nums = sorted([int(n) for n in data['result']])[:6]
                    draws.append({
                        'numbers': nums,
                        'id': data.get('id', ''),
                        'date': data.get('date', ''),
                    })
            except:
                continue
    return draws


def analyze_frequency_bias(draws, max_num, prod_name):
    """Test 1: Chi-squared test - sá»‘ nÃ o xuáº¥t hiá»‡n nhiá»u/Ã­t hÆ¡n ká»³ vá»ng?"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 1: FREQUENCY BIAS (Chi-squared) - {prod_name}")
    print(f"{'='*70}")
    
    freq = Counter()
    for d in draws:
        freq.update(d['numbers'])
    
    total_drawn = sum(freq.values())
    expected = total_drawn / max_num
    
    # Chi-squared test
    observed = [freq.get(i, 0) for i in range(1, max_num + 1)]
    chi2, p_value = stats.chisquare(observed)
    
    print(f"  ğŸ“Š Tá»•ng sá»‘ láº§n quay: {len(draws)}")
    print(f"  ğŸ“Š Ká»³ vá»ng má»—i sá»‘: {expected:.1f} láº§n")
    print(f"  ğŸ“Š Chi-squared: {chi2:.2f}, p-value: {p_value:.6f}")
    
    if p_value < 0.05:
        print(f"  âš ï¸  Káº¾T QUáº¢: CÃ“ THIÃŠN Lá»†CH THá»NG KÃŠ (p < 0.05)")
        print(f"       â†’ PhÃ¢n bá»‘ KHÃ”NG Ä‘á»u - cÃ³ thá»ƒ cÃ³ bias!")
    elif p_value < 0.10:
        print(f"  ğŸŸ¡ Káº¾T QUáº¢: Gáº¦N THIÃŠN Lá»†CH (0.05 < p < 0.10)")
    else:
        print(f"  âœ… Káº¾T QUáº¢: PhÃ¢n bá»‘ Ä‘á»“ng Ä‘á»u (p = {p_value:.4f})")
    
    # Top sá»‘ xuáº¥t hiá»‡n nhiá»u/Ã­t nháº¥t
    sorted_freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n  ğŸ”¥ TOP 10 sá»‘ xuáº¥t hiá»‡n NHIá»€U nháº¥t:")
    for num, count in sorted_freq[:10]:
        deviation = (count - expected) / expected * 100
        bar = "â–ˆ" * int(count / expected * 15)
        print(f"      Sá»‘ {num:2d}: {count:4d} láº§n ({deviation:+.1f}% vs ká»³ vá»ng) {bar}")
    
    print(f"\n  â„ï¸  TOP 10 sá»‘ xuáº¥t hiá»‡n ÃT nháº¥t:")
    for num, count in sorted_freq[-10:]:
        deviation = (count - expected) / expected * 100
        print(f"      Sá»‘ {num:2d}: {count:4d} láº§n ({deviation:+.1f}% vs ká»³ vá»ng)")
    
    # Anomaly detection: sá»‘ nÃ o lá»‡ch > 2 sigma?
    std_freq = np.std(observed)
    mean_freq = np.mean(observed)
    anomalies = []
    for num in range(1, max_num + 1):
        z_score = (freq.get(num, 0) - mean_freq) / std_freq
        if abs(z_score) > 2:
            anomalies.append((num, freq.get(num, 0), z_score))
    
    if anomalies:
        print(f"\n  ğŸš¨ Sá» Báº¤T THÆ¯á»œNG (|z| > 2 sigma):")
        for num, count, z in sorted(anomalies, key=lambda x: abs(x[2]), reverse=True):
            label = "NÃ“NG" if z > 0 else "Láº NH"
            print(f"      Sá»‘ {num:2d}: z={z:+.2f} ({label}) - {count} láº§n")
    
    return freq, anomalies


def analyze_position_bias(draws, max_num, prod_name):
    """Test 2: Position Bias - sá»‘ nÃ o thÆ°á»ng xuáº¥t hiá»‡n á»Ÿ vá»‹ trÃ­ nÃ o?"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 2: POSITION BIAS - {prod_name}")
    print(f"{'='*70}")
    
    pos_freq = defaultdict(lambda: Counter())
    for d in draws:
        sorted_nums = sorted(d['numbers'])
        for pos, num in enumerate(sorted_nums):
            pos_freq[pos][num] += 1
    
    print(f"  ğŸ“Š PhÃ¢n tÃ­ch thiÃªn vá»‹ vá»‹ trÃ­ (sá»‘ Ä‘Æ°á»£c sáº¯p xáº¿p tÄƒng dáº§n):")
    
    biased_positions = []
    for pos in range(6):
        counts = pos_freq[pos]
        top3 = counts.most_common(3)
        total = sum(counts.values())
        expected_per_num = total / max_num
        
        # Chi-squared for this position
        observed = [counts.get(i, 0) for i in range(1, max_num + 1)]
        chi2, p_val = stats.chisquare(observed)
        
        print(f"\n    Vá»‹ trÃ­ {pos+1} (nhá»â†’lá»›n):")
        print(f"      Chi2={chi2:.1f}, p={p_val:.4f}", end="")
        if p_val < 0.01:
            print(" âš ï¸ CÃ“ BIAS Máº NH!")
            biased_positions.append(pos)
        elif p_val < 0.05:
            print(" ğŸŸ¡ CÃ³ bias nháº¹")
        else:
            print(" âœ… OK")
        
        for num, cnt in top3:
            pct = cnt / total * 100
            print(f"      â†’ Sá»‘ {num:2d} chiáº¿m {pct:.1f}% ({cnt}/{total})")
    
    return biased_positions


def analyze_autocorrelation(draws, max_num, prod_name):
    """Test 3: Autocorrelation - ká»³ sau cÃ³ liÃªn quan ká»³ trÆ°á»›c?"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 3: AUTOCORRELATION (TÆ°Æ¡ng quan giá»¯a cÃ¡c ká»³) - {prod_name}")
    print(f"{'='*70}")
    
    # Chuyá»ƒn thÃ nh binary vectors
    vectors = []
    for d in draws:
        vec = np.zeros(max_num)
        for n in d['numbers']:
            vec[n-1] = 1
        vectors.append(vec)
    
    vectors = np.array(vectors)
    
    # Test autocorrelation á»Ÿ cÃ¡c lag khÃ¡c nhau
    print(f"  ğŸ“Š TÆ°Æ¡ng quan giá»¯a ká»³ t vÃ  ká»³ t+lag:")
    
    significant_lags = []
    for lag in range(1, 21):
        if lag >= len(vectors):
            break
        correlations = []
        for num_idx in range(max_num):
            series = vectors[:, num_idx]
            corr = np.corrcoef(series[:-lag], series[lag:])[0, 1]
            if not np.isnan(corr):
                correlations.append(corr)
        
        avg_corr = np.mean(correlations) if correlations else 0
        max_corr = max(correlations) if correlations else 0
        
        emoji = "ğŸ”´" if abs(avg_corr) > 0.05 else ("ğŸŸ¡" if abs(avg_corr) > 0.02 else "â¬œ")
        bar = "â–ˆ" * int(abs(avg_corr) * 200)
        print(f"    Lag {lag:2d}: avg_corr={avg_corr:+.4f} max_corr={max_corr:+.4f} {emoji} {bar}")
        
        if abs(avg_corr) > 0.03:
            significant_lags.append((lag, avg_corr))
    
    if significant_lags:
        print(f"\n  ğŸš¨ LAG CÃ“ TÆ¯Æ NG QUAN:")
        for lag, corr in significant_lags:
            direction = "CÃ™NG CHIá»€U" if corr > 0 else "NGÆ¯á»¢C CHIá»€U"
            print(f"      Lag {lag}: r={corr:+.4f} ({direction})")
            if corr > 0:
                print(f"      â†’ Sá»‘ xuáº¥t hiá»‡n ká»³ trÆ°á»›c cÃ³ xu hÆ°á»›ng xuáº¥t hiá»‡n láº¡i sau {lag} ká»³!")
            else:
                print(f"      â†’ Sá»‘ xuáº¥t hiá»‡n ká»³ trÆ°á»›c ÃT xuáº¥t hiá»‡n sau {lag} ká»³!")
    else:
        print(f"\n  âœ… KhÃ´ng tÃ¬m tháº¥y autocorrelation Ä‘Ã¡ng ká»ƒ")
    
    return significant_lags


def analyze_gap_patterns(draws, max_num, prod_name):
    """Test 4: Gap Analysis - khoáº£ng cÃ¡ch xuáº¥t hiá»‡n cÃ³ chu ká»³ khÃ´ng?"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 4: GAP ANALYSIS (Chu ká»³ xuáº¥t hiá»‡n) - {prod_name}")
    print(f"{'='*70}")
    
    # TÃ­nh gap cho má»—i sá»‘
    gaps = defaultdict(list)
    last_seen = {}
    
    for i, d in enumerate(draws):
        for num in d['numbers']:
            if num in last_seen:
                gap = i - last_seen[num]
                gaps[num].append(gap)
            last_seen[num] = i
    
    # PhÃ¢n tÃ­ch gap distribution
    print(f"\n  ğŸ“Š Thá»‘ng kÃª khoáº£ng cÃ¡ch (gap) giá»¯a cÃ¡c láº§n xuáº¥t hiá»‡n:")
    
    all_gaps = []
    gap_stats = {}
    for num in range(1, max_num + 1):
        if gaps[num]:
            mean_gap = np.mean(gaps[num])
            std_gap = np.std(gaps[num])
            max_gap = max(gaps[num])
            min_gap = min(gaps[num])
            all_gaps.extend(gaps[num])
            gap_stats[num] = {
                'mean': mean_gap, 'std': std_gap, 
                'max': max_gap, 'min': min_gap,
                'cv': std_gap / mean_gap if mean_gap > 0 else 0  # coefficient of variation
            }
    
    # TÃ¬m sá»‘ cÃ³ khoáº£ng cÃ¡ch Ä‘á»u Ä‘áº·n nháº¥t (CV tháº¥p nháº¥t)
    sorted_by_regularity = sorted(gap_stats.items(), key=lambda x: x[1]['cv'])
    
    print(f"\n  â° TOP 10 sá»‘ cÃ³ CHU Ká»² Äá»€U Äáº¶N nháº¥t (Coefficient of Variation tháº¥p nháº¥t):")
    for num, st in sorted_by_regularity[:10]:
        print(f"      Sá»‘ {num:2d}: Mean gap={st['mean']:.1f}, Std={st['std']:.1f}, CV={st['cv']:.3f} ({'Ráº¥t Ä‘á»u!' if st['cv'] < 0.4 else 'TÆ°Æ¡ng Ä‘á»‘i Ä‘á»u' if st['cv'] < 0.6 else 'KhÃ¡ ngáº«u nhiÃªn'})")
    
    # TÃ¬m sá»‘ "quÃ¡ háº¡n" - gap hiá»‡n táº¡i > mean + 1.5*std
    print(f"\n  ğŸ”¥ Sá» 'QUÃ Háº N' (chÆ°a xuáº¥t hiá»‡n lÃ¢u báº¥t thÆ°á»ng):")
    overdue = []
    current_gap = {}
    for num in range(1, max_num + 1):
        if num in last_seen:
            current_gap[num] = len(draws) - 1 - last_seen[num]
    
    for num, cg in current_gap.items():
        if num in gap_stats:
            st = gap_stats[num]
            z = (cg - st['mean']) / st['std'] if st['std'] > 0 else 0
            if z > 1.5:
                overdue.append((num, cg, st['mean'], z))
    
    overdue.sort(key=lambda x: x[3], reverse=True)
    for num, cg, mean_g, z in overdue[:10]:
        print(f"      Sá»‘ {num:2d}: ÄÃ£ {cg} ká»³ chÆ°a xuáº¥t hiá»‡n (Mean={mean_g:.1f}, z={z:.1f}Ïƒ)")
    
    if not overdue:
        print("      KhÃ´ng cÃ³ sá»‘ quÃ¡ háº¡n Ä‘Ã¡ng ká»ƒ")
    
    return gap_stats, overdue


def analyze_pair_correlation(draws, max_num, prod_name):
    """Test 5: Pair Correlation - cáº·p sá»‘ nÃ o hay Ä‘i cÃ¹ng?"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 5: PAIR CORRELATION - {prod_name}")
    print(f"{'='*70}")
    
    pair_count = Counter()
    freq = Counter()
    n_draws = len(draws)
    
    for d in draws:
        nums = d['numbers']
        freq.update(nums)
        for pair in combinations(nums, 2):
            pair_count[tuple(sorted(pair))] += 1
    
    # TÃ­nh expected pair frequency
    # P(A and B) expected = P(A) * P(B) * adjustment
    # For 6/max_num: P(pair) = C(max_num-2, 4) / C(max_num, 6)
    
    significant_pairs = []
    for pair, count in pair_count.items():
        a, b = pair
        # Expected co-occurrence under independence
        p_a = freq[a] / n_draws
        p_b = freq[b] / n_draws
        expected = p_a * p_b * n_draws * (6*5) / (max_num * (max_num-1)) * max_num * (max_num-1) / (6*5)
        # Simpler: expected = n_draws * C(max_num-2, 4) / C(max_num, 6)
        expected_simple = n_draws * 6 * 5 / (max_num * (max_num - 1))
        
        if expected_simple > 0:
            ratio = count / expected_simple
            if ratio > 1.8 or ratio < 0.3:
                significant_pairs.append((pair, count, expected_simple, ratio))
    
    # Top pairs
    top_pairs = pair_count.most_common(15)
    print(f"\n  ğŸ”— TOP 15 cáº·p sá»‘ HAY ÄI CÃ™NG nháº¥t:")
    for pair, count in top_pairs:
        expected_simple = n_draws * 6 * 5 / (max_num * (max_num - 1))
        ratio = count / expected_simple
        bar = "â–ˆ" * int(ratio * 10)
        emoji = "ğŸ”´" if ratio > 1.5 else ("ğŸŸ¡" if ratio > 1.2 else "â¬œ")
        print(f"      ({pair[0]:2d}, {pair[1]:2d}): {count:3d} láº§n (Ã—{ratio:.2f} vs ká»³ vá»ng) {emoji} {bar}")
    
    if significant_pairs:
        print(f"\n  ğŸš¨ Cáº¶P Sá» Báº¤T THÆ¯á»œNG (ratio > 1.8x hoáº·c < 0.3x):")
        significant_pairs.sort(key=lambda x: x[3], reverse=True)
        for pair, count, exp, ratio in significant_pairs[:10]:
            label = "HAY ÄI CÃ™NG" if ratio > 1 else "HIáº¾M ÄI CÃ™NG"
            print(f"      ({pair[0]:2d}, {pair[1]:2d}): {count} láº§n vs ká»³ vá»ng {exp:.1f} (Ã—{ratio:.2f}) â†’ {label}")
    
    return significant_pairs


def analyze_sum_patterns(draws, max_num, prod_name):
    """Test 6: Sum & Modular Patterns"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 6: SUM & MODULAR PATTERNS - {prod_name}")
    print(f"{'='*70}")
    
    sums = [sum(d['numbers']) for d in draws]
    
    print(f"\n  ğŸ“Š Thá»‘ng kÃª tá»•ng:")
    print(f"      Mean: {np.mean(sums):.1f}")
    print(f"      Std: {np.std(sums):.1f}")
    print(f"      Min: {min(sums)}, Max: {max(sums)}")
    print(f"      P25: {np.percentile(sums, 25):.0f}, P50: {np.percentile(sums, 50):.0f}, P75: {np.percentile(sums, 75):.0f}")
    
    # Test normality
    _, p_norm = stats.normaltest(sums)
    print(f"      Normality test p-value: {p_norm:.6f} ({'PhÃ¢n bá»‘ chuáº©n âœ…' if p_norm > 0.05 else 'KHÃ”NG phÃ¢n bá»‘ chuáº©n âš ï¸'})")
    
    # Sum mod patterns
    print(f"\n  ğŸ”¢ PhÃ¢n tÃ­ch SUM mod N:")
    for mod in [3, 5, 7, 10]:
        remainders = [s % mod for s in sums]
        dist = Counter(remainders)
        expected = len(sums) / mod
        chi2, p = stats.chisquare([dist.get(i, 0) for i in range(mod)])
        
        emoji = "âš ï¸ BIAS!" if p < 0.05 else "âœ… OK"
        print(f"      Sum mod {mod}: chi2={chi2:.1f}, p={p:.4f} {emoji}")
        if p < 0.05:
            most_common = dist.most_common(1)[0]
            print(f"         â†’ DÆ° {most_common[0]} xuáº¥t hiá»‡n {most_common[1]} láº§n ({most_common[1]/len(sums)*100:.1f}%)")
    
    # Consecutive sum trends
    print(f"\n  ğŸ“ˆ Trend tá»•ng liÃªn tiáº¿p:")
    sum_diffs = [sums[i+1] - sums[i] for i in range(len(sums)-1)]
    up_count = sum(1 for d in sum_diffs if d > 0)
    down_count = sum(1 for d in sum_diffs if d < 0)
    equal_count = sum(1 for d in sum_diffs if d == 0)
    
    print(f"      TÄƒng: {up_count} ({up_count/len(sum_diffs)*100:.1f}%)")
    print(f"      Giáº£m: {down_count} ({down_count/len(sum_diffs)*100:.1f}%)")
    print(f"      Báº±ng: {equal_count} ({equal_count/len(sum_diffs)*100:.1f}%)")
    
    return sums


def analyze_day_of_week(draws, prod_name):
    """Test 7: Day-of-week bias"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 7: DAY-OF-WEEK BIAS - {prod_name}")
    print(f"{'='*70}")
    
    day_freq = defaultdict(lambda: Counter())
    day_count = Counter()
    day_names = ['T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'CN']
    
    for d in draws:
        try:
            date = datetime.strptime(d['date'], '%Y-%m-%d')
            dow = date.weekday()
            day_count[dow] += 1
            day_freq[dow].update(d['numbers'])
        except:
            continue
    
    if not day_count:
        print("  âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch ngÃ y (thiáº¿u dá»¯ liá»‡u date)")
        return
    
    print(f"\n  ğŸ“… PhÃ¢n bá»‘ quay theo ngÃ y:")
    for dow in range(7):
        count = day_count.get(dow, 0)
        if count > 0:
            print(f"      {day_names[dow]}: {count} ká»³")
    
    # TÃ¬m sá»‘ nÃ o hay ra vÃ o ngÃ y nÃ o
    print(f"\n  ğŸ“Š Sá»‘ hay xuáº¥t hiá»‡n theo ngÃ y (top 3 má»—i ngÃ y):")
    for dow in sorted(day_count.keys()):
        if day_count[dow] >= 10:  # Cáº§n Ã­t nháº¥t 10 ká»³
            top3 = day_freq[dow].most_common(3)
            total = sum(day_freq[dow].values())
            top_str = ", ".join([f"Sá»‘ {n}({c})" for n, c in top3])
            print(f"      {day_names[dow]}: {top_str}")


def analyze_transition_matrix(draws, max_num, prod_name):
    """Test 8: Transition patterns - sau sá»‘ X thÆ°á»ng ra sá»‘ gÃ¬?"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 8: TRANSITION PATTERNS - {prod_name}")
    print(f"{'='*70}")
    
    # Track: náº¿u sá»‘ X xuáº¥t hiá»‡n ká»³ nÃ y, sá»‘ nÃ o hay xuáº¥t hiá»‡n ká»³ sau?
    transitions = defaultdict(Counter)
    
    for i in range(len(draws) - 1):
        current = draws[i]['numbers']
        next_draw = draws[i + 1]['numbers']
        for num in current:
            transitions[num].update(next_draw)
    
    print(f"\n  ğŸ“Š Sau sá»‘ X, sá»‘ nÃ o hay xuáº¥t hiá»‡n nháº¥t?")
    
    strong_transitions = []
    for num in range(1, max_num + 1):
        if transitions[num]:
            total = sum(transitions[num].values())
            top = transitions[num].most_common(3)
            expected_per = total / max_num
            
            for next_num, count in top:
                ratio = count / expected_per if expected_per > 0 else 0
                if ratio > 1.5:
                    strong_transitions.append((num, next_num, count, expected_per, ratio))
    
    strong_transitions.sort(key=lambda x: x[4], reverse=True)
    
    print(f"\n  ğŸ”— TOP 15 transition Máº NH nháº¥t (ratio > 1.5x):")
    for num, next_num, count, exp, ratio in strong_transitions[:15]:
        print(f"      Sá»‘ {num:2d} â†’ Sá»‘ {next_num:2d}: {count} láº§n (Ã—{ratio:.2f} vs ká»³ vá»ng)")
    
    return strong_transitions


def analyze_hot_cold_streaks(draws, max_num, prod_name):
    """Test 9: Hot/Cold streaks - chuá»—i nÃ³ng láº¡nh"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 9: HOT/COLD STREAKS - {prod_name}")
    print(f"{'='*70}")
    
    # TÃ­nh max streak (xuáº¥t hiá»‡n liÃªn tiáº¿p) cho má»—i sá»‘
    max_hot = {}  # max consecutive appearances
    max_cold = {}  # max consecutive absences
    
    for num in range(1, max_num + 1):
        hot_streak = 0
        cold_streak = 0
        max_h = 0
        max_c = 0
        
        for d in draws:
            if num in d['numbers']:
                hot_streak += 1
                if cold_streak > max_c:
                    max_c = cold_streak
                cold_streak = 0
            else:
                cold_streak += 1
                if hot_streak > max_h:
                    max_h = hot_streak
                hot_streak = 0
        
        max_h = max(max_h, hot_streak)
        max_c = max(max_c, cold_streak)
        max_hot[num] = max_h
        max_cold[num] = max_c
    
    # Top hot streaks
    sorted_hot = sorted(max_hot.items(), key=lambda x: x[1], reverse=True)
    print(f"\n  ğŸ”¥ TOP 10 chuá»—i NÃ“NG dÃ i nháº¥t (xuáº¥t hiá»‡n liÃªn tiáº¿p):")
    for num, streak in sorted_hot[:10]:
        bar = "â–ˆ" * streak
        print(f"      Sá»‘ {num:2d}: {streak} ká»³ liÃªn tiáº¿p {bar}")
    
    # Top cold streaks
    sorted_cold = sorted(max_cold.items(), key=lambda x: x[1], reverse=True)
    print(f"\n  â„ï¸  TOP 10 chuá»—i Láº NH dÃ i nháº¥t (váº¯ng máº·t liÃªn tiáº¿p):")
    for num, streak in sorted_cold[:10]:
        print(f"      Sá»‘ {num:2d}: {streak} ká»³ váº¯ng máº·t")
    
    # Current streaks (for prediction)
    print(f"\n  ğŸ¯ STREAK HIá»†N Táº I (dÃ¹ng cho dá»± Ä‘oÃ¡n):")
    current_hot = {}
    current_cold = {}
    
    for num in range(1, max_num + 1):
        streak = 0
        for d in reversed(draws):
            if num in d['numbers']:
                streak += 1
            else:
                break
        current_hot[num] = streak
        
        streak = 0
        for d in reversed(draws):
            if num not in d['numbers']:
                streak += 1
            else:
                break
        current_cold[num] = streak
    
    hot_now = [(n, s) for n, s in current_hot.items() if s >= 2]
    hot_now.sort(key=lambda x: x[1], reverse=True)
    if hot_now:
        print(f"    ğŸ”¥ Äang NÃ“NG (xuáº¥t hiá»‡n â‰¥2 ká»³ liÃªn tiáº¿p):")
        for num, streak in hot_now:
            print(f"        Sá»‘ {num:2d}: {streak} ká»³ liÃªn tiáº¿p")
    
    cold_now = [(n, s) for n, s in current_cold.items() if s >= 15]
    cold_now.sort(key=lambda x: x[1], reverse=True)
    if cold_now:
        print(f"    â„ï¸  Äang Láº NH (váº¯ng máº·t â‰¥15 ká»³):")
        for num, streak in cold_now[:10]:
            print(f"        Sá»‘ {num:2d}: {streak} ká»³ váº¯ng máº·t")
    
    return current_hot, current_cold


def analyze_even_odd_pattern(draws, prod_name):
    """Test 10: Even/Odd & High/Low patterns"""
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ TEST 10: EVEN/ODD & HIGH/LOW PATTERNS - {prod_name}")
    print(f"{'='*70}")
    
    even_counts = []
    high_counts = []
    max_num = max(max(d['numbers']) for d in draws)
    mid = max_num // 2
    
    for d in draws:
        evens = sum(1 for n in d['numbers'] if n % 2 == 0)
        highs = sum(1 for n in d['numbers'] if n > mid)
        even_counts.append(evens)
        high_counts.append(highs)
    
    # Even/Odd distribution
    even_dist = Counter(even_counts)
    print(f"\n  ğŸ“Š PhÃ¢n bá»‘ Cháºµn/Láº»:")
    for ec in range(7):
        count = even_dist.get(ec, 0)
        pct = count / len(draws) * 100
        bar = "â–ˆ" * int(pct / 2)
        print(f"      {ec}C/{6-ec}L: {count:4d} ({pct:5.1f}%) {bar}")
    
    # Consecutive even/odd patterns
    print(f"\n  ğŸ“ˆ Xu hÆ°á»›ng cháºµn/láº» liÃªn tiáº¿p:")
    same_count = 0
    for i in range(1, len(even_counts)):
        if even_counts[i] == even_counts[i-1]:
            same_count += 1
    pct_same = same_count / (len(even_counts) - 1) * 100
    print(f"      Tá»· lá»‡ giá»¯ nguyÃªn cháºµn/láº»: {pct_same:.1f}%")
    
    # High/Low distribution
    high_dist = Counter(high_counts)
    print(f"\n  ğŸ“Š PhÃ¢n bá»‘ Cao/Tháº¥p (>{mid}):")
    for hc in range(7):
        count = high_dist.get(hc, 0)
        pct = count / len(draws) * 100
        bar = "â–ˆ" * int(pct / 2)
        print(f"      {hc}C/{6-hc}T: {count:4d} ({pct:5.1f}%) {bar}")


def generate_prediction_from_patterns(freq_anomalies, gap_overdue, transitions, 
                                       current_hot, current_cold, max_num, prod_name):
    """Tá»•ng há»£p táº¥t cáº£ patterns thÃ nh dá»± Ä‘oÃ¡n."""
    print(f"\n{'='*70}")
    print(f"ğŸ¯ Tá»”NG Há»¢P Dá»° ÄOÃN Tá»ª REVERSE ENGINEERING - {prod_name}")
    print(f"{'='*70}")
    
    scores = defaultdict(float)
    reasons = defaultdict(list)
    
    # 1. Frequency anomalies (hot numbers)
    for num, count, z in freq_anomalies:
        if z > 0:  # Hot numbers
            scores[num] += z * 0.3
            reasons[num].append(f"Freq anomaly z={z:.1f}")
    
    # 2. Overdue numbers (gap analysis)
    for num, cg, mean_g, z in gap_overdue:
        scores[num] += z * 0.25
        reasons[num].append(f"Overdue {cg} ká»³ (z={z:.1f})")
    
    # 3. Current hot streaks
    for num, streak in current_hot.items():
        if streak >= 2:
            scores[num] += streak * 0.5
            reasons[num].append(f"Hot streak {streak}")
    
    # 4. Current cold (contrarian - might be due)
    for num, streak in current_cold.items():
        if streak >= 12:
            scores[num] += (streak - 10) * 0.1
            reasons[num].append(f"Cold {streak} ká»³ (due?)")
    
    # 5. Strong transitions from last draw
    for num, next_num, count, exp, ratio in transitions[:30]:
        scores[next_num] += (ratio - 1) * 0.2
        reasons[next_num].append(f"Transition tá»« {num} (Ã—{ratio:.1f})")
    
    # Sort and display
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n  ğŸ† TOP 20 sá»‘ Ä‘Æ°á»£c RE khuyÃªn chá»n:")
    for num, score in sorted_scores[:20]:
        reason_str = " | ".join(reasons[num][:3])
        bar = "â–ˆ" * int(score * 5)
        print(f"      Sá»‘ {num:2d}: Score={score:.2f} {bar}")
        print(f"            LÃ½ do: {reason_str}")
    
    return sorted_scores


def main():
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  ğŸ”¬ DEEP REVERSE ENGINEERING v2.0 - TÃŒM QUY LUáº¬T áº¨N    â•‘")
    print("â•‘  PhÃ¢n tÃ­ch 10 yáº¿u tá»‘ thá»‘ng kÃª chuyÃªn sÃ¢u               â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"  ğŸ“… {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    for product_type in ["power_645", "power_655"]:
        max_num = 55 if "655" in product_type else 45
        filename = "power655.jsonl" if "655" in product_type else "power645.jsonl"
        prod_name = "POWER 6/55" if "655" in product_type else "MEGA 6/45"
        
        filepath = os.path.join(os.getcwd(), 'data', filename)
        if not os.path.exists(filepath):
            filepath = os.path.join(base_dir, '..', '..', '..', 'data', filename)
        
        if not os.path.exists(filepath):
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y {filename}")
            continue
        
        draws = load_draws(filepath)
        
        print(f"\n\n{'#'*70}")
        print(f"### REVERSE ENGINEERING: {prod_name} ({len(draws)} ká»³) ###")
        print(f"{'#'*70}")
        
        # Run all tests
        freq, anomalies = analyze_frequency_bias(draws, max_num, prod_name)
        analyze_position_bias(draws, max_num, prod_name)
        autocorr = analyze_autocorrelation(draws, max_num, prod_name)
        gap_stats, overdue = analyze_gap_patterns(draws, max_num, prod_name)
        pairs = analyze_pair_correlation(draws, max_num, prod_name)
        analyze_sum_patterns(draws, max_num, prod_name)
        analyze_day_of_week(draws, prod_name)
        transitions = analyze_transition_matrix(draws, max_num, prod_name)
        current_hot, current_cold = analyze_hot_cold_streaks(draws, max_num, prod_name)
        analyze_even_odd_pattern(draws, prod_name)
        
        # Synthesize predictions
        generate_prediction_from_patterns(
            anomalies, overdue, transitions,
            current_hot, current_cold, max_num, prod_name
        )
    
    print(f"\n\n{'='*70}")
    print("âœ… HOÃ€N Táº¤T REVERSE ENGINEERING!")
    print("ğŸ’¡ DÃ¹ng káº¿t quáº£ trÃªn Ä‘á»ƒ tinh chá»‰nh thuáº­t toÃ¡n Ultra Predictor")
    print(f"{'='*70}")


if __name__ == "__main__":
    main()
